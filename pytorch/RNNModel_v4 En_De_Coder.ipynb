{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简介\n",
    "当输入序列长度和输出标签序列长度都可变时(即输入序列的子序列个数和输出序列的子序列个数不同)\n",
    "\n",
    "数据预处理:\n",
    "指定子序列长度,填充<pad>词元或裁剪得到固定长度的子序列,增加<eos>词元至子序列末尾\n",
    "\n",
    "encoder(编码器):\n",
    "1.子序列(batchsize,num_steps,vocabsize)用embeding层降维至(batchsize,num_steps,embed_size) #num_steps是子序列的词元个数,即RNN的时间步骤个数\n",
    "2.子序列(batchsize,num_steps,vocabsize)输出为(batchsize,num_steps,num_hiddens)和每个子序列的末尾时间步骤的状态(batchsize,num_layers,num_hiddens) #num_hidddens是隐藏层特征数,num_layers是RNN层数\n",
    "\n",
    "decoder(编码器):(N个长度固定的子序列->batchsize个为一批次,子序列长度为num_steps)\n",
    "1.子序列(batchsize,num_steps,vocabsize)用embeding层降维至(batchsize,num_steps,embed_size) #num_steps是子序列的词元个数,即RNN的时间步骤个数\n",
    "2.取encoder输出的最后一个时间步骤的预测的特征(batchsize,num_hiddens),添加为decoder子序列的特征(batchsize,num_steps,embed_size+num_hiddens) #decoder的每个时间步都包含encoder的特征?\n",
    "3.拼接后的decoder子序列(batchsize,num_steps,embed_size+num_hiddens)的RNN输出为(batchsize,num_steps,num_hiddens),并通过linear层转为(batchsize,num_steps,vocabsize),其中RNN初始状态是encoder的末尾时间步骤的状态(batchsize,num_layers,num_hiddens) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lit_encoder(pl.LightningModule):\n",
    "    def __init__(self,vocab_size,embed_size,num_hiddens,num_layers,dropout=0):\n",
    "        super(Lit_encoder,self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(vocab_size,embed_size)\n",
    "        self.rnn = torch.nn.GRU(embed_size,num_hiddens,num_layers,batch_first=True,dropout=dropout)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.embedding(x)\n",
    "        outputs,state = self.rnn(x)\n",
    "        #outputs: (batch_size,num_steps,num_hiddens)\n",
    "        #state: (batch_size,num_layers,num_hiddens)\n",
    "        return outputs, state\n",
    "\n",
    "class Lit_decoder(pl.LightningModule):\n",
    "    def __init__(self,vocab_size,embed_size,num_hiddens,num_layers,dropout=0):\n",
    "        super(Lit_decoder,self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(vocab_size,embed_size)\n",
    "        self.rnn = torch.nn.GRU(embed_size+num_hiddens,num_hiddens,num_layers,batch_first=True,dropout=dropout)\n",
    "        self.dense = torch.nn.Linear(num_hiddens,vocab_size)\n",
    "    \n",
    "    def forward(self,x,state):\n",
    "        x = self.embedding(x) #size: (batch_size,num_steps,embed_size)\n",
    "        enc_outputs, enc_state = state\n",
    "        #context=enc_outputs[-1]  #d2l的enc_outputs是[nums_step,batch_size,num_hiddens]\n",
    "        context=enc_outputs[:,-1,:]  #size: (batch_size,num_hiddens)\n",
    "        context=context.unsqueeze(1) #size: (batch_size,1,num_hiddens)\n",
    "        context=context.repeat(1,x.shape[1],1) #size: (batch_size,num_steps,num_hiddens)\n",
    "        x=torch.cat((x,context),2)\n",
    "        outputs,dec_state = self.rnn(x,enc_state)\n",
    "        outputs=self.dense(outputs) #size: (batch_size,num_steps,vocab_size)\n",
    "        return outputs, [enc_outputs,dec_state]\n",
    "\n",
    "class Lit_encoder_decoder(pl.LightningModule):\n",
    "    def __init__(self,encoder,decoder,lr=0.001,tgt_pad_id=0):\n",
    "        super(Lit_encoder_decoder,self).__init__()\n",
    "        self.encoder=encoder\n",
    "        self.decoder=decoder\n",
    "        self.lr=lr\n",
    "        self.tgt_pad_id=tgt_pad_id\n",
    "        torch.nn.MultiheadAttention\n",
    "\n",
    "    def loss(self,y_pred,y):\n",
    "        l=torch.nn.functional.cross_entropy(y_pred.view(-1,y_pred.shape[-1]),y.view(-1))\n",
    "        mask=(y.view(-1)!=self.tgt_pad_id).float()\n",
    "        l=l*mask\n",
    "        return l.sum()/mask.sum()\n",
    "\n",
    "    def forward(self,enc_x,dec_x):\n",
    "        enc_result=self.encoder(enc_x)\n",
    "        dec_result=self.decoder(dec_x,enc_result)\n",
    "        return dec_result[0]\n",
    "\n",
    "    def training_step(self,batch,batch_idx):\n",
    "        x,y=batch\n",
    "        y_pred=self(x,y) \n",
    "        loss=self.loss(y_pred,y)\n",
    "        self.log('train_loss',loss, prog_bar=True, logger=True, on_epoch=True,on_step=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        x,y=batch\n",
    "        y_pred=self(x,y)\n",
    "        loss=self.loss(y_pred,y)\n",
    "        self.log('val_loss',loss, prog_bar=True, logger=True, on_epoch=True,on_step=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(),lr=self.lr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d2l的数据集处理方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go.\tVa !\n",
      "Hi.\tSalut !\n",
      "Run!\tCours !\n",
      "Run!\tCourez !\n",
      "Who?\tQui ?\n",
      "Wow!\tÇa alors !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "import re\n",
    "import zipfile\n",
    "class LitLoadData_fra_impl(pl.LightningDataModule):  \n",
    "    def prepare_data(self):\n",
    "        url = 'http://d2l-data.s3-accelerate.amazonaws.com/fra-eng.zip'\n",
    "        #文件是否存在\n",
    "        if os.path.exists('./data/fra-eng/fra.txt'):\n",
    "            return\n",
    "        #下载文件\n",
    "        r = requests.get(url, stream=True)\n",
    "        #解压文件\n",
    "        with zipfile.ZipFile('./data/fra-eng.zip', 'r') as zip_ref:\n",
    "            zip_ref.extractall('./data/fra-eng')\n",
    "            \n",
    "data=LitLoadData_fra_impl()\n",
    "data.prepare_data()\n",
    "#返回fra.txt内容\n",
    "with open('./data/fra-eng/fra.txt', 'r', encoding='utf-8') as f:\n",
    "    raw_txt = f.read()\n",
    "print(raw_txt[:75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['go', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['hi', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['run', '!', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['run', '!', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['who', '?', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['wow', '!', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']]\n",
      "[['<bos>', 'va', '!', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<bos>', 'salut', '!', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<bos>', 'cours', '!', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<bos>', 'courez', '!', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<bos>', 'qui', '?', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<bos>', 'ça', 'alors', '!', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def preprocess(raw_txt,max_tokens=10000,num_steps=9):\n",
    "    #大写字母改为小写\n",
    "    raw_txt=raw_txt.lower()\n",
    "    #去掉空行,取前max_tokens行\n",
    "    lines=raw_txt.split('\\n')\n",
    "    lines=[line for line in lines if len(line)>0]\n",
    "    lines=lines[:max_tokens]\n",
    "    #每行以 tab 分割为两组\n",
    "    pairs=[line.split('\\t') for line in lines]\n",
    "    #删除空行\n",
    "    pairs=[pair for pair in pairs if len(pair)==2]\n",
    "    #每组单词分割,标点符号视为一个独立单词\n",
    "    pairs=[[re.findall(r'\\w+|[^\\w\\s]',pair[0]),re.findall(r'\\w+|[^\\w\\s]',pair[1])] for pair in pairs]\n",
    "    #返回源语言和目标语言\n",
    "    src=[pair[0] for pair in pairs]\n",
    "    tgt=[pair[1] for pair in pairs]\n",
    "    #末尾添加特殊字符'<eos>'\n",
    "    src=[pair+['<eos>'] for pair in src]\n",
    "    tgt=[pair+['<eos>'] for pair in tgt]\n",
    "    #tgt前面添加特殊字符'<bos>'\n",
    "    tgt=[['<bos>']+pair for pair in tgt]\n",
    "    #裁剪或填充'<pad>'至num_steps\n",
    "    src=[pair[:num_steps]+['<pad>']*(num_steps-len(pair)) if len(pair)<num_steps else pair[:num_steps] for pair in src]\n",
    "    tgt=[pair[:num_steps]+['<pad>']*(num_steps-len(pair)) if len(pair)<num_steps else pair[:num_steps] for pair in tgt]\n",
    "    return src,tgt\n",
    "\n",
    "\n",
    "LitLoadData_fra_impl.preprocess=preprocess \n",
    "\n",
    "src,tgt=preprocess(raw_txt,max_tokens=10000,num_steps=9)\n",
    "print(src[:6])\n",
    "print(tgt[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', '<eos>', '.', 'i', \"'\"]\n",
      "['<unk>', '<pad>', '<bos>', '<eos>', '.', \"'\"]\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "def vocab(sentences, min_freq=0):\n",
    "    tokens = [token for sentence in sentences for token in sentence]\n",
    "    counter = collections.Counter(tokens)\n",
    "    # 去掉频率小于min_freq的单词\n",
    "    tokens = [token for token in counter if counter[token] >= min_freq] \n",
    "    # token的idx按频率降序\n",
    "    tokens = sorted(tokens, key=lambda x: counter[x], reverse=True)\n",
    "    idx_to_token = ['<unk>'] + tokens\n",
    "    token_to_idx = {token: idx for idx, token in enumerate(idx_to_token)}\n",
    "    return idx_to_token, token_to_idx\n",
    "\n",
    "LitLoadData_fra_impl.vocab=vocab\n",
    "\n",
    "idx_to_token_src, token_to_idx_src = vocab(src)\n",
    "idx_to_token_tgt, token_to_idx_tgt = vocab(tgt)\n",
    "print(idx_to_token_src[:6])\n",
    "print(idx_to_token_tgt[:6])\n",
    "#print(token_to_idx_src['<d>'])  #todo: nokey的token是<unk>\n",
    "\n",
    "print(token_to_idx_src['go']) #0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitLoadData_fra(LitLoadData_fra_impl):\n",
    "    def __init__(self,batch_size=64,num_steps=9,num_trains=512,num_val=128):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.prepare_data() #download txt\n",
    "        with open('./data/fra-eng/fra.txt', 'r', encoding='utf-8') as f:\n",
    "            self.raw_txt = f.read()\n",
    "        self.src,self.tgt=preprocess(raw_txt= self.raw_txt,max_tokens= num_trains+num_val,num_steps=num_steps)\n",
    "        self.idx_to_token_src,self.token_to_idx_src=vocab(self.src)\n",
    "        self.idx_to_token_tgt,self.token_to_idx_tgt=vocab(self.tgt)\n",
    "        self.src_idx=[[self.token_to_idx_src[token] for token in sentence] for sentence in self.src]\n",
    "        self.tgt_idx=[[self.token_to_idx_tgt[token] for token in sentence] for sentence in self.tgt]\n",
    "        self.src_idx=torch.tensor(self.src_idx)\n",
    "        self.tgt_idx=torch.tensor(self.tgt_idx)\n",
    "\n",
    "    def get_tgtpad_idx(self):\n",
    "        return self.token_to_idx_tgt['<pad>']\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        src=self.src_idx[:self.hparams.num_trains]\n",
    "        tgt=self.tgt_idx[:self.hparams.num_trains]\n",
    "        dataset = torch.utils.data.TensorDataset(src, tgt)\n",
    "        return torch.utils.data.DataLoader(dataset, batch_size=self.hparams.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        src=self.src_idx[self.hparams.num_trains:]\n",
    "        tgt=self.tgt_idx[self.hparams.num_trains:]\n",
    "        dataset = torch.utils.data.TensorDataset(src, tgt)\n",
    "        return torch.utils.data.DataLoader(dataset, batch_size=self.hparams.batch_size, shuffle=False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用tokenizers训练文本自动提取token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<bos>', '/', 'x', '0', '20', 'd', '<eos>', '<pad>', '<pad>']\n",
      "<pad> <bos> <eos> <unk> ! \"\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "from tokenizers.pre_tokenizers import BertPreTokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "\n",
    "class TokenizerTrainer:\n",
    "    def __init__(self, num_step=9):\n",
    "        self.num_step = num_step\n",
    "        self.tokenizer = Tokenizer(BPE())\n",
    "        self.tokenizer.pre_tokenizer = BertPreTokenizer()\n",
    "        self.tokenizer.add_special_tokens([\"<pad>\", \"<bos>\", \"<eos>\", \"<unk>\"])\n",
    "        self.trainer = BpeTrainer(special_tokens=[\"<pad>\", \"<bos>\", \"<eos>\", \"<unk>\"], min_frequency=2)\n",
    "        self.tokenizer.enable_padding(pad_id=self.tokenizer.token_to_id(\"<pad>\"), pad_token=\"<pad>\", length=self.num_step)\n",
    "        self.tokenizer.enable_truncation(max_length=self.num_step)\n",
    "        self.tokenizer.post_processor = TemplateProcessing(\n",
    "            single=\"<bos> $A <eos>\",\n",
    "            pair=\"<bos> $A <eos> <bos> $B <eos>\",\n",
    "            special_tokens=[\n",
    "                (\"<bos>\", self.tokenizer.token_to_id(\"<bos>\")),\n",
    "                (\"<eos>\", self.tokenizer.token_to_id(\"<eos>\")),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    def train(self, file_path):\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "        pairs = [line.split('\\t') for line in lines]\n",
    "        self.tokenizer.train_from_iterator(pairs, self.trainer)\n",
    "\n",
    "    def save(self, path):\n",
    "        self.tokenizer.save(path)\n",
    "\n",
    "    def encode(self, text):\n",
    "        return self.tokenizer.encode(text)\n",
    "\n",
    "    def decode(self, ids, skip_special_tokens=True):\n",
    "        return self.tokenizer.decode(ids, skip_special_tokens=skip_special_tokens)\n",
    "\n",
    "tokenizer = TokenizerTrainer()\n",
    "tokenizer.train('./data/fra-eng/fra.txt')\n",
    "tokenizer.save('./data/fra-eng/tokenizer.json')\n",
    "print(tokenizer.encode('/x020d').tokens) #todo: 是否应该是<unk>? 是和否对模型训练有影响吗?\n",
    "print(tokenizer.decode([0, 1, 2, 3, 4, 5],skip_special_tokens=False)) #todo: 这里的skip_special_tokens=True是否应该是False? 是和否对模型训练有影响吗?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\zncyxiong\\AppData\\Local\\anaconda3\\envs\\pytorch_python3128\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:654: Checkpoint directory D:\\algorithm\\deeplearning_zh.d2l.ai\\pytorch\\checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type        | Params | Mode \n",
      "------------------------------------------------\n",
      "0 | encoder | Lit_encoder | 860 K  | train\n",
      "1 | decoder | Lit_decoder | 1.3 M  | train\n",
      "------------------------------------------------\n",
      "2.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 M     Total params\n",
      "8.463     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zncyxiong\\AppData\\Local\\anaconda3\\envs\\pytorch_python3128\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\zncyxiong\\AppData\\Local\\anaconda3\\envs\\pytorch_python3128\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\zncyxiong\\AppData\\Local\\anaconda3\\envs\\pytorch_python3128\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:310: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 4/4 [00:00<00:00, 47.62it/s, v_num=17, train_loss_step=0.00225, val_loss_step=1.220, val_loss_epoch=1.220, train_loss_epoch=0.00232] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 4/4 [00:00<00:00, 44.44it/s, v_num=17, train_loss_step=0.00225, val_loss_step=1.220, val_loss_epoch=1.220, train_loss_epoch=0.00232]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    data = LitLoadData_fra(batch_size=128, num_steps=9, num_trains=512, num_val=128)\n",
    "    encoder = Lit_encoder(len(data.idx_to_token_src),embed_size=256,num_hiddens=256,num_layers=2,dropout=0.2)\n",
    "    decoder = Lit_decoder(len(data.idx_to_token_tgt),embed_size=256,num_hiddens=256,num_layers=2,dropout=0.2)\n",
    "    model = Lit_encoder_decoder(encoder, decoder,lr=0.005)\n",
    "    \n",
    "    logger = TensorBoardLogger(\"tensorBoard-logs/\", name=\"RNNModel_v4\")\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor='val_loss',\n",
    "        dirpath='checkpoints',\n",
    "        filename='RNNModel_v4_{epoch:02d}_{val_loss:.2f}',\n",
    "       # save_top_k=3,\n",
    "        mode='min',\n",
    "    )\n",
    "    trainer = pl.Trainer(max_epochs=30,gradient_clip_algorithm='norm',gradient_clip_val=1, logger=logger, callbacks=[checkpoint_callback])\n",
    "    trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 1344), started 0:10:20 ago. (Use '!kill 1344' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-29a053bfdf38dfe\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-29a053bfdf38dfe\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir ./tensorBoard-logs/RNNModel_v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000,\n",
       "         0.9000, 1.0000, 1.1000, 1.2000, 1.3000, 1.4000, 1.5000, 1.6000, 1.7000,\n",
       "         1.8000, 1.9000, 2.0000, 2.1000, 2.2000, 2.3000, 2.4000, 2.5000, 2.6000,\n",
       "         2.7000, 2.8000, 2.9000, 3.0000, 3.1000, 3.2000, 3.3000, 3.4000, 3.5000,\n",
       "         3.6000, 3.7000, 3.8000, 3.9000, 4.0000, 4.1000, 4.2000, 4.3000, 4.4000,\n",
       "         4.5000, 4.6000, 4.7000, 4.8000, 4.9000]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x):\n",
    "    return 2 * torch.sin(x) + x\n",
    "\n",
    "n = 40\n",
    "x_train, _ = torch.sort(torch.rand(n) * 5)\n",
    "y_train = f(x_train) + torch.randn(n)\n",
    "x_val = torch.arange(0, 5, 0.1)\n",
    "y_val = f(x_val)\n",
    "x_train.reshape((-1, 1)) #shape: (40, 1)\n",
    "x_val.reshape((1, -1)) #shape: (1, 50)\n",
    "dists = x_train.reshape((-1, 1)) - x_val.reshape((1, -1)) #shape: (40, 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_python3128",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
