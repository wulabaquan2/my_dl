{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any \n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "#lightning\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics import MeanMetric\n",
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.profilers import PyTorchProfiler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "用pytorch-lightning包装classModel_v2_api.py\n",
    "数据集配置参数模块\n",
    "训练配置参数模块\n",
    "基于LightningDataModule的数据加载和数据集定义模块\n",
    "基于LightningModule的模型定义模块\n",
    "基于TensorBoardLogger的日志记录模块\n",
    "基于ModelCheckpoint的模型保存模块\n",
    "基于PyTorchProfiler的性能分析模块\n",
    "基于pytorch_lightning.Trainer的训练器来集成上述模块\n",
    "'''\n",
    "\n",
    "class DataConfiguration:\n",
    "    batch_size:int=32\n",
    "    num_classes:int=10\n",
    "    train_valid_ratio:float=0.8\n",
    "    data_root:str=\"../data\"\n",
    "    num_workers:int=4\n",
    "\n",
    "class TrainConfiguration:\n",
    "    lr:float=0.1\n",
    "    optimizer:str=\"SGD\"\n",
    "    epochs:int=5\n",
    "    train_logs:str=\"tensorBoard-logs/\"\n",
    "\n",
    "#alias TrainConfiguration to train_config\n",
    "train_config=TrainConfiguration()\n",
    "\n",
    "#custom transform\n",
    "def img_prerpocess_transform():\n",
    "    return transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "#数据模块\n",
    "class LitDataModule(pl.LightningDataModule):\n",
    "    def __init__(self,data_config:DataConfiguration):\n",
    "        super().__init__()\n",
    "        self.data_config=data_config\n",
    "        self.train_transform=img_prerpocess_transform()\n",
    "        self.test_transform=img_prerpocess_transform()\n",
    "    \n",
    "    #下载数据集\n",
    "    def prepare_data(self) -> None:\n",
    "        torchvision.datasets.FashionMNIST(\n",
    "            root=self.data_config.data_root,\n",
    "            train=True,#train set\n",
    "            transform=self.train_transform,\n",
    "            download=True\n",
    "        )\n",
    "        torchvision.datasets.FashionMNIST(\n",
    "            root=self.data_config.data_root,\n",
    "            train=False,#test set\n",
    "            transform=self.test_transform,\n",
    "            download=True\n",
    "        )\n",
    "    #数据加载\n",
    "    def setup(self,stage=None):\n",
    "        if stage==\"fit\" or stage is None:\n",
    "            data=torchvision.datasets.FashionMNIST(\n",
    "                root=self.data_config.data_root,\n",
    "                train=True,\n",
    "                transform=self.train_transform,\n",
    "            )\n",
    "            num_train=int(len(data)*self.data_config.train_valid_ratio)\n",
    "            num_valid=len(data)-num_train\n",
    "            self.train_data,self.valid_data=torch.utils.data.random_split(data,[num_train,num_valid])\n",
    "        if stage==\"test\" or stage is None:\n",
    "            self.test_data=torchvision.datasets.FashionMNIST(\n",
    "                root=self.data_config.data_root,\n",
    "                train=False,\n",
    "                transform=self.test_transform)\n",
    "   \n",
    "\n",
    "    #生成数据加载器\n",
    "    def train_dataloader(self):\n",
    "        return data.DataLoader(self.train_data,batch_size=self.data_config.batch_size,shuffle=True,num_workers=self.data_config.num_workers,persistent_workers=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return data.DataLoader(self.valid_data,batch_size=self.data_config.batch_size,shuffle=False,num_workers=self.data_config.num_workers,persistent_workers=True)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return data.DataLoader(self.test_data,batch_size=self.data_config.batch_size,shuffle=False,num_workers=self.data_config.num_workers)  \n",
    "\n",
    "#模型模块\n",
    "class LitClassModel(pl.LightningModule):\n",
    "    def __init__(self,train_config:TrainConfiguration):\n",
    "        super().__init__()\n",
    "        self.train_config=train_config\n",
    "        self.model=nn.Sequential(nn.Flatten(),nn.Linear(784,10))\n",
    "        self.model.apply(self.init_weights)#初始化参数\n",
    "        self.loss=nn.CrossEntropyLoss(reduction='none')    \n",
    "        #指标\n",
    "        self.mean_train_loss=MeanMetric()#平均损失\n",
    "        self.mean_train_acc=MulticlassAccuracy(num_classes=10)#多分类准确率\n",
    "        self.mean_valid_loss=MeanMetric()#验证集平均损失\n",
    "        self.mean_valid_acc=MulticlassAccuracy(num_classes=10)#验证集多分类准确率\n",
    "\n",
    "    def init_weights(self,m):\n",
    "        if type(m)==nn.Linear:\n",
    "            nn.init.normal_(m.weight,std=0.01)\n",
    "\n",
    "    def forward(self,data):\n",
    "        return self.model(data)\n",
    "    \n",
    "    def training_step(self, batch, *args, **kwargs):\n",
    "        X, y = batch\n",
    "        y_hat = self(X)\n",
    "        loss = self.loss(y_hat, y).mean()\n",
    "        # 记录batch日志\n",
    "        self.mean_train_loss.update(loss.item(), X.shape[0])\n",
    "        self.mean_train_acc.update(y_hat.detach().argmax(dim=1), y)\n",
    "        # self.log(\"train/batch_loss\", self.mean_train_loss, prog_bar=True, logger=True)\n",
    "        # self.log(\"train/batch_acc\", self.mean_train_acc, prog_bar=True, logger=True)\n",
    "        return loss.mean()\n",
    "  \n",
    "   \n",
    "    #每个epoch结束后调用\n",
    "    def on_train_epoch_end(self) -> None:\n",
    "        #记录epoch日志\n",
    "        # Computing and logging the training mean loss & mean f1.\n",
    "        train_loss=self.mean_train_loss.compute()\n",
    "        train_acc=self.mean_train_acc.compute()\n",
    "        self.log(\"train/loss\", train_loss, prog_bar=True, logger=True)\n",
    "        self.log(\"train/acc\", train_acc, prog_bar=True, logger=True)\n",
    "        self.log(\"step\", self.current_epoch, logger=True) \n",
    "\n",
    "    #验证集评估\n",
    "    def validation_step(self,batch, *args: Any, **kwargs: Any):\n",
    "        X,y=batch\n",
    "        y_hat=self(X)\n",
    "        loss=self.loss(y_hat,y).mean()\n",
    "        #记录batch日志\n",
    "        self.mean_valid_loss.update(loss.item(),X.shape[0])\n",
    "        self.mean_valid_acc.update(y_hat.detach().argmax(dim=1),y)\n",
    "        self.log(\"valid/batch_loss\",self.mean_valid_loss,prog_bar=True,logger=True)\n",
    "        self.log(\"valid/batch_acc\",self.mean_valid_acc,prog_bar=True,logger=True)\n",
    "        return loss\n",
    "\n",
    "    #每个epoch结束后调用\n",
    "    def on_validation_epoch_end(self) -> None:\n",
    "        # Computing and logging the validation mean loss & mean f1.\n",
    "        val_loss=self.mean_valid_loss.compute()\n",
    "        val_acc=self.mean_valid_acc.compute()\n",
    "        self.log(\"valid/loss\", val_loss, prog_bar=True, logger=True)\n",
    "        self.log(\"valid/acc\", val_acc, prog_bar=True, logger=True)\n",
    "        self.log(\"step\", self.current_epoch, logger=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer=getattr(torch.optim,self.train_config.optimizer)(\n",
    "            self.model.parameters(),\n",
    "            lr=self.train_config.lr\n",
    "        )\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\zncyxiong\\AppData\\Local\\anaconda3\\envs\\pytorch_python3128\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:654: Checkpoint directory D:\\algorithm\\deeplearning_zh.d2l.ai\\pytorch\\checkPoint-logs exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type               | Params | Mode \n",
      "---------------------------------------------------------------\n",
      "0 | model           | Sequential         | 7.9 K  | train\n",
      "1 | loss            | CrossEntropyLoss   | 0      | train\n",
      "2 | mean_train_loss | MeanMetric         | 0      | train\n",
      "3 | mean_train_acc  | MulticlassAccuracy | 0      | train\n",
      "4 | mean_valid_loss | MeanMetric         | 0      | train\n",
      "5 | mean_valid_acc  | MulticlassAccuracy | 0      | train\n",
      "---------------------------------------------------------------\n",
      "7.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.9 K     Total params\n",
      "0.031     Total estimated model params size (MB)\n",
      "8         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1500/1500 [00:15<00:00, 98.08it/s, v_num=0, valid/batch_loss=0.437, valid/batch_acc=0.849, valid/loss=0.437, valid/acc=0.849, train/loss=0.512, train/acc=0.826] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1500/1500 [00:15<00:00, 97.97it/s, v_num=0, valid/batch_loss=0.437, valid/batch_acc=0.849, valid/loss=0.437, valid/acc=0.849, train/loss=0.512, train/acc=0.826]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "        \n",
    "    #固定随机种子,保证实验可复现性\n",
    "    pl.seed_everything(42,workers=True)\n",
    "\n",
    "    #创建数据模块\n",
    "    data_module=LitDataModule(DataConfiguration())\n",
    "    data_module.prepare_data()#下载数据\n",
    "    data_module.setup()#加载数据\n",
    "\n",
    "    #创建模型\n",
    "    model=LitClassModel(train_config)\n",
    "\n",
    "    #监控某个指标,每次达到最好时保存当前模型\n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        monitor=\"valid/acc\",  #监控验证集的acc\n",
    "        mode=\"max\",  #{min,max},监控acc用max,监控loss用min\n",
    "        dirpath='checkPoint-logs/',\n",
    "        filename=\"classModel_v4_{epoch:03d}_{valid/acc:.2f}\",\n",
    "        auto_insert_metric_name=False, #false用于自定义filename\n",
    "        save_weights_only=True\n",
    "    )\n",
    "\n",
    "    #创建tensorboard日志\n",
    "    tb_logger = TensorBoardLogger(save_dir=train_config.train_logs, name=\"classModel_v4\")\n",
    "\n",
    "    #创建性能分析器\n",
    "    profiler = PyTorchProfiler(dirpath=train_config.train_logs,filename=\"classModel_v4_profiler\")\n",
    "    #profiler2=AdvancedProfiler(dirpath=train_config.train_logs,filename=\"classModel_v4_advancedProfiler\") #一直提示: ValueError: Another profiling tool is already active\n",
    "    \n",
    "    #创建训练器\n",
    "    trainer=pl.Trainer(\n",
    "        accelerator=\"auto\",#自动选择加速器\n",
    "        devices=\"auto\",#自动选择设备\n",
    "        strategy=\"auto\",#自动选择策略\n",
    "        max_epochs=train_config.epochs,#最大训练轮数\n",
    "        profiler=profiler,#性能分析器\n",
    "        logger=tb_logger,#tensorboard日志\n",
    "        callbacks=[model_checkpoint],#回调函数\n",
    "        enable_model_summary=True#启用模型摘要 \n",
    "    )\n",
    "\n",
    "    #开始训练\n",
    "    trainer.fit(model,data_module)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
